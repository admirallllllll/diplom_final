{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8403722,
          "sourceType": "datasetVersion",
          "datasetId": 5000516
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import networkx as nx\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.image as mpimg\n",
        "import random"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-15T10:42:08.254253Z",
          "iopub.execute_input": "2024-05-15T10:42:08.254647Z",
          "iopub.status.idle": "2024-05-15T10:42:27.815128Z",
          "shell.execute_reply.started": "2024-05-15T10:42:08.254608Z",
          "shell.execute_reply": "2024-05-15T10:42:27.813719Z"
        },
        "trusted": true,
        "id": "yj_nNi4iDvff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_excel('/content/vitrina_clusters.xlsx')\n",
        "#dataset = dataset[:400]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:42:27.823556Z",
          "iopub.execute_input": "2024-05-15T10:42:27.824009Z",
          "iopub.status.idle": "2024-05-15T10:43:19.804080Z",
          "shell.execute_reply.started": "2024-05-15T10:42:27.823963Z",
          "shell.execute_reply": "2024-05-15T10:43:19.802562Z"
        },
        "trusted": true,
        "id": "_CDYS3UkDvfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "wWUH8149Dvfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"cluster\"].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:47:34.543700Z",
          "iopub.execute_input": "2024-05-15T10:47:34.544160Z",
          "iopub.status.idle": "2024-05-15T10:47:34.562167Z",
          "shell.execute_reply.started": "2024-05-15T10:47:34.544124Z",
          "shell.execute_reply": "2024-05-15T10:47:34.560658Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT5TZ3dNDvfj",
        "outputId": "a7593997-e595-4566-ac5f-f95f8d849ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cluster\n",
              "0    75394\n",
              "5    12730\n",
              "3      697\n",
              "4       60\n",
              "2        6\n",
              "1        1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df1 = dataset[dataset['cluster'] == 0]\n",
        "#df2 = dataset[dataset['cluster'] == 1]\n",
        "#df3 = dataset[dataset['cluster'] == 2]\n",
        "df4 = dataset[dataset['cluster'] == 3]\n",
        "df5 = dataset[dataset['cluster'] == 4]\n",
        "df6 = dataset[dataset['cluster'] == 5]\n",
        "\n",
        "X1_train, X1_test = train_test_split(df1,test_size=0.2, random_state=42)\n",
        "#X2_train, X2_test = train_test_split(df2,test_size=0.2, random_state=42)\n",
        "#X3_train, X3_test = train_test_split(df3,test_size=0.2, random_state=42)\n",
        "X4_train, X4_test = train_test_split(df4,test_size=0.2, random_state=42)\n",
        "X5_train, X5_test = train_test_split(df5,test_size=0.2, random_state=42)\n",
        "X6_train, X6_test = train_test_split(df6,test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:44:52.777505Z",
          "iopub.execute_input": "2024-05-15T10:44:52.778582Z",
          "iopub.status.idle": "2024-05-15T10:44:52.880851Z",
          "shell.execute_reply.started": "2024-05-15T10:44:52.778519Z",
          "shell.execute_reply": "2024-05-15T10:44:52.879332Z"
        },
        "trusted": true,
        "id": "TPJ7CtZhDvfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def creating_graph(dataset):\n",
        "    G = nx.Graph()\n",
        "    node2index = {}\n",
        "    node_counter = 0\n",
        "\n",
        "    some_unique_id = \"000-000\"\n",
        "    G.add_node(node_counter,type='user') #- вершина для тестового набора данных\n",
        "    node2index[some_unique_id] = node_counter\n",
        "    node_counter += 1\n",
        "\n",
        "    items = ['%TN_Автотовары', '%TN_Аксессуары', '%TN_Детские товары', '%TN_Игры, софт и развлечения', '%TN_Климат', '%TN_Крупная бытовая техника', '%TN_Мебель', '%TN_Мелкая бытовая техника', '%TN_Сделай сам', '%TN_Спорт и активный отдых', '%TN_ТВ-Аудио', '%TN_Товары для дома', '%TN_Услуги', '%TN_Хобби, досуг', '%TN_Цифровая Техника', '%TN_Элитная техника']\n",
        "\n",
        "    for i in items:\n",
        "        G.add_node(node_counter, type='item')\n",
        "        node2index[i] = node_counter\n",
        "        node_counter += 1\n",
        "\n",
        "    for index, row in dataset.iterrows():\n",
        "        G.add_node(node_counter, type='user')\n",
        "        node2index[row['Phone_new']] = node_counter\n",
        "        for i in items:\n",
        "            G.add_edge(node_counter, node2index[i], weight=row[i])\n",
        "        node_counter += 1\n",
        "\n",
        "    return G, node2index\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:44:55.203840Z",
          "iopub.execute_input": "2024-05-15T10:44:55.204310Z",
          "iopub.status.idle": "2024-05-15T10:44:55.215758Z",
          "shell.execute_reply.started": "2024-05-15T10:44:55.204279Z",
          "shell.execute_reply": "2024-05-15T10:44:55.214262Z"
        },
        "trusted": true,
        "id": "S-WY_GHdDvfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def biased_random_walk(G, start_node, walk_length, p=1, q=1):\n",
        "    walk = [start_node]\n",
        "\n",
        "    while len(walk) < walk_length:\n",
        "        cur_node = walk[-1]\n",
        "        cur_neighbors = list(G.neighbors(cur_node))\n",
        "\n",
        "        if len(cur_neighbors) > 0:\n",
        "            if len(walk) == 1:\n",
        "                walk.append(random.choice(cur_neighbors))\n",
        "            else:\n",
        "                prev_node = walk[-2]\n",
        "\n",
        "                probability = []\n",
        "                for neighbor in cur_neighbors:\n",
        "                    if neighbor == prev_node:\n",
        "                        # Return parameter\n",
        "                        probability.append(1/p)\n",
        "                    elif G.has_edge(neighbor, prev_node):\n",
        "                        # Stay parameter\n",
        "                        probability.append(1)\n",
        "                    else:\n",
        "                        # In-out parameter\n",
        "                        probability.append(1/q)\n",
        "\n",
        "                probability = np.array(probability)\n",
        "                probability = probability / probability.sum()  # normalize\n",
        "\n",
        "                next_node = np.random.choice(cur_neighbors, p=probability)\n",
        "                walk.append(next_node)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return walk"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:44:58.152124Z",
          "iopub.execute_input": "2024-05-15T10:44:58.152571Z",
          "iopub.status.idle": "2024-05-15T10:44:58.163704Z",
          "shell.execute_reply.started": "2024-05-15T10:44:58.152538Z",
          "shell.execute_reply": "2024-05-15T10:44:58.162522Z"
        },
        "trusted": true,
        "id": "0T-UtAEEDvfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_walks(G, num_walks, walk_length, p=1, q=1):\n",
        "    walks = []\n",
        "    nodes = list(G.nodes())\n",
        "    for _ in range(num_walks):\n",
        "        random.shuffle(nodes)  # to ensure randomness\n",
        "        for node in nodes:\n",
        "            walk_from_node = biased_random_walk(G, node, walk_length, p, q)\n",
        "            walks.append(walk_from_node)\n",
        "    return walks"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:45:00.716080Z",
          "iopub.execute_input": "2024-05-15T10:45:00.716535Z",
          "iopub.status.idle": "2024-05-15T10:45:00.723621Z",
          "shell.execute_reply.started": "2024-05-15T10:45:00.716500Z",
          "shell.execute_reply": "2024-05-15T10:45:00.722293Z"
        },
        "trusted": true,
        "id": "tR2y8iEODvfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pygsp"
      ],
      "metadata": {
        "trusted": true,
        "id": "vZyUzZJHDvfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def creating_model(G):\n",
        "    walks = generate_walks(G, num_walks=10, walk_length=20, p=9, q=1)\n",
        "    filtered_walks = [walk for walk in walks if len(walk) >= 5]\n",
        "\n",
        "    # to String  (for Word2Vec input)\n",
        "    walks = [[str(node) for node in walk] for walk in walks]\n",
        "\n",
        "    # Word2Vec train\n",
        "    model = Word2Vec(walks, vector_size=128, window=5, min_count=0,  hs=1, sg=1, workers=4, epochs=10)\n",
        "\n",
        "    # node embedding extract\n",
        "    embeddings = {node_id: model.wv[node_id] for node_id in model.wv.index_to_key}\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:45:03.121367Z",
          "iopub.execute_input": "2024-05-15T10:45:03.121835Z",
          "iopub.status.idle": "2024-05-15T10:45:03.131014Z",
          "shell.execute_reply.started": "2024-05-15T10:45:03.121801Z",
          "shell.execute_reply": "2024-05-15T10:45:03.129615Z"
        },
        "trusted": true,
        "id": "VkuczVrSDvfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G1, node_index1 = creating_graph(X1_train)\n",
        "G4, node_index4 = creating_graph(X4_train)\n",
        "G5, node_index5 = creating_graph(X5_train)\n",
        "G6, node_index6 = creating_graph(X6_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:45:06.109808Z",
          "iopub.execute_input": "2024-05-15T10:45:06.110260Z",
          "iopub.status.idle": "2024-05-15T10:45:21.750403Z",
          "shell.execute_reply.started": "2024-05-15T10:45:06.110225Z",
          "shell.execute_reply": "2024-05-15T10:45:21.748833Z"
        },
        "trusted": true,
        "id": "y3bNmOcADvfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model1 = creating_model(G1)\n",
        "#model4 = creating_model(G4)\n",
        "#model5 = creating_model(G5)\n",
        "model6 = creating_model(G6)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:48:21.736264Z",
          "iopub.execute_input": "2024-05-15T10:48:21.737759Z",
          "iopub.status.idle": "2024-05-15T11:07:57.585849Z",
          "shell.execute_reply.started": "2024-05-15T10:48:21.737702Z",
          "shell.execute_reply": "2024-05-15T11:07:57.583901Z"
        },
        "trusted": true,
        "id": "b4m8UiH5Dvfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#embeddings1 = {node_id: model1.wv[node_id] for node_id in model1.wv.index_to_key}\n",
        "#embeddings4 = {node_id: model4.wv[node_id] for node_id in model4.wv.index_to_key}\n",
        "#embeddings5 = {node_id: model5.wv[node_id] for node_id in model5.wv.index_to_key}\n",
        "embeddings6 = {node_id: model6.wv[node_id] for node_id in model6.wv.index_to_key}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:46:25.819158Z",
          "iopub.execute_input": "2024-05-15T10:46:25.819827Z",
          "iopub.status.idle": "2024-05-15T10:46:25.826731Z",
          "shell.execute_reply.started": "2024-05-15T10:46:25.819783Z",
          "shell.execute_reply": "2024-05-15T10:46:25.825515Z"
        },
        "trusted": true,
        "id": "_QcbOy7sDvfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_embedding(user_id, embeddings):\n",
        "    return embeddings[str(user_id)]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:46:28.936819Z",
          "iopub.execute_input": "2024-05-15T10:46:28.937474Z",
          "iopub.status.idle": "2024-05-15T10:46:28.943019Z",
          "shell.execute_reply.started": "2024-05-15T10:46:28.937418Z",
          "shell.execute_reply": "2024-05-15T10:46:28.941423Z"
        },
        "trusted": true,
        "id": "J_JxzM6kDvfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rated_items(user_id, df, item, items):\n",
        "    return df[df['Phone_new'] == user_id][item]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:46:30.707752Z",
          "iopub.execute_input": "2024-05-15T10:46:30.708408Z",
          "iopub.status.idle": "2024-05-15T10:46:30.714084Z",
          "shell.execute_reply.started": "2024-05-15T10:46:30.708376Z",
          "shell.execute_reply": "2024-05-15T10:46:30.712544Z"
        },
        "trusted": true,
        "id": "OW8PSzHaDvfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_similarities(user_id, df, embeddings, items):\n",
        "    for item in items:\n",
        "        rated_items = get_rated_items(user_id, df, item, items)\n",
        "    user_embedding = get_user_embedding(user_id, embeddings)\n",
        "\n",
        "    item_similarities = []\n",
        "    for item_id in items:\n",
        "        if item_id not in rated_items:\n",
        "            item_embedding = embeddings[item_id]\n",
        "            similarity = cosine_similarity([user_embedding], [item_embedding])[0][0]\n",
        "            item_similarities.append((item_id, similarity))\n",
        "\n",
        "    return item_similarities"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:46:32.762332Z",
          "iopub.execute_input": "2024-05-15T10:46:32.762774Z",
          "iopub.status.idle": "2024-05-15T10:46:32.771090Z",
          "shell.execute_reply.started": "2024-05-15T10:46:32.762741Z",
          "shell.execute_reply": "2024-05-15T10:46:32.769524Z"
        },
        "trusted": true,
        "id": "fJpspNxgDvfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_items(user_id, df, embeddings, items, num_items=5):\n",
        "    for item in items:\n",
        "        rated_items = get_rated_items(user_id, df, item, items)\n",
        "\n",
        "    #print(f\"User {user_id} has purchased:\")\n",
        "    #print(rated_items)\n",
        "\n",
        "    item_similarities = calculate_similarities(user_id, df, embeddings, items)\n",
        "\n",
        "    recommended_items = sorted(item_similarities, key=lambda x: x[1], reverse=True)[:num_items]\n",
        "\n",
        "    #print(f\"\\nRecommended items for user {user_id}:\")\n",
        "    #print(recommended_items)\n",
        "    return recommended_items"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:46:36.210250Z",
          "iopub.execute_input": "2024-05-15T10:46:36.210670Z",
          "iopub.status.idle": "2024-05-15T10:46:36.217972Z",
          "shell.execute_reply.started": "2024-05-15T10:46:36.210640Z",
          "shell.execute_reply": "2024-05-15T10:46:36.216731Z"
        },
        "trusted": true,
        "id": "LK97BVQODvfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "items = ['%TN_Автотовары', '%TN_Аксессуары', '%TN_Детские товары', '%TN_Игры, софт и развлечения', '%TN_Климат', '%TN_Крупная бытовая техника', '%TN_Мебель', '%TN_Мелкая бытовая техника', '%TN_Сделай сам', '%TN_Спорт и активный отдых', '%TN_ТВ-Аудио', '%TN_Товары для дома', '%TN_Услуги', '%TN_Хобби, досуг', '%TN_Цифровая Техника', '%TN_Элитная техника']\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:46:53.540612Z",
          "iopub.execute_input": "2024-05-15T10:46:53.541102Z",
          "iopub.status.idle": "2024-05-15T10:46:53.547457Z",
          "shell.execute_reply.started": "2024-05-15T10:46:53.541065Z",
          "shell.execute_reply": "2024-05-15T10:46:53.546325Z"
        },
        "trusted": true,
        "id": "1FNud0clDvfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#recommends1 = recommend_items(0, df1, embeddings1, items, num_items=16)\n",
        "#recommends4 = recommend_items(0, df4, embeddings4, items, num_items=16)\n",
        "#recommends5 = recommend_items(0, df5, embeddings5, items, num_items=16)\n",
        "recommends6 = recommend_items(0, df6, embeddings6, items, num_items=16)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T10:46:54.986840Z",
          "iopub.execute_input": "2024-05-15T10:46:54.987393Z",
          "iopub.status.idle": "2024-05-15T10:46:55.121564Z",
          "shell.execute_reply.started": "2024-05-15T10:46:54.987350Z",
          "shell.execute_reply": "2024-05-15T10:46:55.119151Z"
        },
        "trusted": true,
        "id": "IIvGPVp3Dvfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommends1, recommends4, recommends5, recommends6"
      ],
      "metadata": {
        "trusted": true,
        "id": "QSvHYGLCDvfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1_test[items]"
      ],
      "metadata": {
        "trusted": true,
        "id": "R-CUYbUsDvfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relevance_score1 = [x[1] for x in recommends1]\n",
        "relevance_score1 = relevance_score1\n",
        "relevance_score1"
      ],
      "metadata": {
        "trusted": true,
        "id": "Vz0pPIZ8Dvfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_at_k(scores, true_relevance, k):\n",
        "\n",
        "    num_users = len(scores)\n",
        "    ap_scores = []\n",
        "\n",
        "    for i in range(num_users):\n",
        "        # Sort the predicted scores by value\n",
        "        sorted_scores = sorted(enumerate(scores[i]), key=lambda x: x[1], reverse=True)\n",
        "        # Get the top k predicted items\n",
        "        top_k_predicted_items = [x[0] for x in sorted_scores[:k]]\n",
        "        # Calculate the average precision\n",
        "        num_relevant_items = sum(1 for j in range(len(true_relevance[i])) if true_relevance[i][j] > 0)\n",
        "        relevant_count = 0\n",
        "        ap = 0\n",
        "        for j in range(k):\n",
        "            if true_relevance[i][top_k_predicted_items[j]] > 0:\n",
        "                relevant_count += 1\n",
        "                ap += relevant_count / (j + 1)\n",
        "        ap_scores.append(ap / min(num_relevant_items, k))\n",
        "\n",
        "    # Calculate the MAP@K score\n",
        "    map_k = np.mean(ap_scores)\n",
        "    return map_k"
      ],
      "metadata": {
        "trusted": true,
        "id": "KJBHH3Q9Dvfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0_PKy6e4Dvfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maps = []\n",
        "for i in range(len(X1_test)):\n",
        "    true_relevance = X1_test[items].iloc[i].values.tolist()\n",
        "    for i in range(len(true_relevance)):\n",
        "        if true_relevance[i] > 0:\n",
        "            true_relevance[i] = 1\n",
        "    map_k = map_at_k([relevance_score1], [true_relevance], 10)\n",
        "    maps.append(map_k)\n",
        "# for i in range(len(maps)):\n",
        "#     if maps[i] == 0:\n",
        "#         maps[i] = 1\n",
        "np.mean(maps)"
      ],
      "metadata": {
        "trusted": true,
        "id": "1l18X4RwDvfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NN GAT GCN\n"
      ],
      "metadata": {
        "id": "5iju5LuvIOuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "\n",
        "class GraphAttentionLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout=0.6, alpha=0.2, concat=True):\n",
        "        super(GraphAttentionLayer, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.alpha = alpha\n",
        "        self.concat = concat\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n",
        "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
        "\n",
        "        self.a = nn.Parameter(torch.zeros(size=(2*out_features, 1)))\n",
        "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        h = torch.matmul(input, self.W)\n",
        "        N = h.size()[0]\n",
        "\n",
        "        a_input = torch.cat([h.repeat(1, N).view(N*N, -1), h.repeat(N, 1)], dim=1).view(N, -1, 2*self.out_features)\n",
        "        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))\n",
        "\n",
        "        zero_vec = -9e15*torch.ones_like(e)\n",
        "        attention = torch.where(adj > 0, e, zero_vec)\n",
        "        attention = F.softmax(attention, dim=1)\n",
        "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
        "        h_prime = torch.matmul(attention, h)\n",
        "\n",
        "        if self.concat:\n",
        "            return F.elu(h_prime)\n",
        "        else:\n",
        "            return h_prime\n",
        "\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout=0.6, alpha=0.2, nheads=8):\n",
        "        super(GAT, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.attentions = [GraphAttentionLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=True) for _ in range(nheads)]\n",
        "        for i, attention in enumerate(self.attentions):\n",
        "            self.add_module('attention_{}'.format(i), attention)\n",
        "\n",
        "        self.out_att = GraphAttentionLayer(nhid*nheads, nclass, dropout=dropout, alpha=alpha, concat=False)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = torch.cat([att(x, adj) for att in self.attentions], dim=1)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.elu(self.out_att(x, adj))\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Example usage\n",
        "G = G6\n",
        "# Generate a random graph using NetworkX\n",
        "adj = nx.adjacency_matrix(G)\n",
        "\n",
        "# Convert adjacency matrix to a PyTorch dense tensor\n",
        "adj_tensor = torch.FloatTensor(adj.todense())\n",
        "\n",
        "# Define node features (random in this example)\n",
        "node_features = torch.randn(G.number_of_nodes(), 16) # Use the number of nodes from your graph\n",
        "\n",
        "# Initialize the GAT model\n",
        "model = GAT(nfeat=16, nhid=8, nclass=2, dropout=0.6, alpha=0.2, nheads=8)\n",
        "\n",
        "# Forward pass\n",
        "\n",
        "embeddings = model(node_features, adj_tensor)\n",
        "embeddings_dict = {node_id: embeddings[index].detach().numpy() for node_id, index in node_index6.items()}\n",
        "\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def recommend_items(user_id, embeddings_dict, top_n=5):\n",
        "    user_embedding = embeddings_dict[user_id]\n",
        "    item_embeddings = [embedding for node_id, embedding in embeddings_dict.items() if node_id != user_id and node_id.startswith('%')]\n",
        "\n",
        "    similarities = cosine_similarity([user_embedding], item_embeddings)\n",
        "    top_indices = np.argsort(similarities[0])[::-1][:top_n]\n",
        "\n",
        "    recommended_items = [(list(embeddings_dict.keys())[i], similarities[0][i]) for i in top_indices]\n",
        "    return recommended_items\n",
        "\n",
        "# Example usage\n",
        "user_id = '000-000'\n",
        "recommended_items = recommend_items(user_id, embeddings_dict)\n",
        "\n",
        "maps = []\n",
        "for i in range(len(X5_test)):\n",
        "    true_relevance = X5_test[items].iloc[i].values.tolist()\n",
        "    for i in range(len(true_relevance)):\n",
        "        if true_relevance[i] > 0:\n",
        "            true_relevance[i] = 1\n",
        "    map_k = map_at_k([recommended_items], [true_relevance], 5)\n",
        "    maps.append(map_k)\n",
        "# for i in range(len(maps)):\n",
        "#     if maps[i] == 0:\n",
        "#         maps[i] = 1\n",
        "np.mean(maps)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T11:10:23.566736Z",
          "iopub.execute_input": "2024-05-15T11:10:23.567261Z"
        },
        "trusted": true,
        "id": "MEwSVVHzDvfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def recommend_items(user_id, embeddings_dict, top_n=10):\n",
        "    user_embedding = embeddings_dict[user_id]\n",
        "    item_embeddings = [embedding for node_id, embedding in embeddings_dict.items() if node_id != user_id and node_id.startswith('%')]\n",
        "\n",
        "    similarities = cosine_similarity([user_embedding], item_embeddings)\n",
        "    top_indices = np.argsort(similarities[0])[::-1][:top_n]\n",
        "\n",
        "    recommended_items = [(list(embeddings_dict.keys())[i], similarities[0][i]) for i in top_indices]\n",
        "    return recommended_items"
      ],
      "metadata": {
        "trusted": true,
        "id": "g_zeffi4Dvfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "\n",
        "\n",
        "class GraphConvolution(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        support = torch.matmul(input, self.weight)\n",
        "        output = torch.matmul(adj, support)\n",
        "        return output\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass):\n",
        "        super(GCN, self).__init__()\n",
        "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
        "        self.gc2 = GraphConvolution(nhid, nclass)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.relu(self.gc1(x, adj))\n",
        "        x = self.gc2(x, adj)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "\n",
        "Gr = G6\n",
        "adj = nx.adjacency_matrix(Gr)\n",
        "\n",
        "# Convert adjacency matrix to a PyTorch sparse tensor\n",
        "adj_tensor = torch.FloatTensor(adj.todense())\n",
        "\n",
        "# Define node features (random in this example)\n",
        "node_features = torch.randn(Gr.number_of_nodes(), 16) # Use the number of nodes from your graph\n",
        "\n",
        "# Initialize the GCN model\n",
        "model = GCN(nfeat=16, nhid=8, nclass=2)\n",
        "\n",
        "# Forward pass to obtain embeddings\n",
        "embeddings = model(node_features, adj_tensor)\n",
        "\n",
        "embeddings_dict = {node_id: embeddings[index].detach().numpy() for node_id, index in node_index6.items()}\n",
        "\n",
        "user_id = \"000-000\"\n",
        "recommended_items = recommend_items(user_id, embeddings_dict)\n",
        "recommended_items"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T11:09:11.019028Z",
          "iopub.execute_input": "2024-05-15T11:09:11.019541Z",
          "iopub.status.idle": "2024-05-15T11:09:15.254056Z",
          "shell.execute_reply.started": "2024-05-15T11:09:11.019497Z",
          "shell.execute_reply": "2024-05-15T11:09:15.252267Z"
        },
        "trusted": true,
        "id": "tl3hM-3uDvfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maps = []\n",
        "for i in range(len(X1_test)):\n",
        "    true_relevance = X1_test[items].iloc[i].values.tolist()\n",
        "#     for i in range(len(true_relevance)):\n",
        "#         if true_relevance[i] > 0:\n",
        "#             true_relevance[i] = 1\n",
        "    map_k = map_at_k([recommended_items], [true_relevance], 10)\n",
        "    maps.append(map_k)\n",
        "# for i in range(len(maps)):\n",
        "#     if maps[i] == 0:\n",
        "#         maps[i] = 1\n",
        "np.mean(maps)"
      ],
      "metadata": {
        "trusted": true,
        "id": "pPpHCLGRDvfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rAV9ZL2zDvfp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}